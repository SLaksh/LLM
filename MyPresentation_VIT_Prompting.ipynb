{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOePyM3pEvmQCq5gZfgyuNI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SLaksh/LLM/blob/main/MyPresentation_VIT_Prompting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q \"google-generativeai>=0.8.3\""
      ],
      "metadata": {
        "id": "Zch67LOLRfPT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rkScSbgJefRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from IPython.display import HTML, Markdown, display"
      ],
      "metadata": {
        "id": "QRLV4IElSYnV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "import google.generativeai as genai\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', ' *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "f9rb5PVOTW-e"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key='mySecret')"
      ],
      "metadata": {
        "id": "GSIrFFXMTqs7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('mySecret')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "ilQgTNxtWICs"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-pro')\n",
        "\n",
        "# Display formatted Markdown response\n",
        "response = model.generate_content(\"Calculate the sum of all prime numbers between 0 and 20.\")\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "aV6pvXxcU3HC",
        "outputId": "a4eb465b-dd5f-4bc8-dce0-899f36e92bec"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> The prime numbers between 0 and 20 are 2, 3, 5, 7, 11, 13, 17, and 19.\n> \n> Their sum is 2 + 3 + 5 + 7 + 11 + 13 + 17 + 19 = 77.\n"
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flash = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = flash.generate_content(\"Explain AI to me like I'm a kid.\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "LUOobMCyT9l3",
        "outputId": "7b6139f3-71cc-40e3-bc09-e3b45ce25ee6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagine you have a really smart puppy.  You teach it tricks, like \"sit\" and \"fetch\".  At first, it's clumsy and makes mistakes. But the more you teach it and show it what to do, the better it gets!\n",
            "\n",
            "Artificial intelligence, or AI, is like that smart puppy, but instead of learning tricks, it learns from information.  We give the computer lots and lots of information – like pictures of cats and dogs, or sentences in different languages.  The computer studies this information and learns to recognize patterns.  \n",
            "\n",
            "So, after seeing lots of pictures of cats, it learns what a cat looks like and can tell the difference between a cat and a dog.  Or, after reading lots of sentences in English and Spanish, it can start to translate between the two languages.\n",
            "\n",
            "It's not actually *thinking* like you and me, but it's getting really good at doing things that usually need a brain, like solving problems and making decisions.  It's still learning and getting better all the time!  AI helps us do lots of cool things, like recommend movies you might like or help doctors diagnose illnesses.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = flash.start_chat(history=[])\n",
        "response = chat.send_message('Hello! My name is Laksh.')\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "pHiNkNKMXsV2",
        "outputId": "5223b5fa-4e1a-4f35-c8c5-71b2b2a420a8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Laksh!  It's nice to meet you.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message('Can you tell something interesting about dinosaurs?')\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "AMqgXUbuXxzC",
        "outputId": "97e0cc9b-de22-414d-c8fa-22a4655fcea7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did you know that some dinosaurs had feathers?  While we often picture dinosaurs as scaly reptiles, many species, particularly theropods (the group that includes *Tyrannosaurus rex*), were covered in feathers, ranging from simple filaments to complex, bird-like plumage.  This discovery has been crucial in understanding the evolutionary link between dinosaurs and birds.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# While you have the `chat` object around, the conversation state\n",
        "# persists. Confirm that by asking if it knows my name.\n",
        "response = chat.send_message('Do you remember what my name is?')\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "P9ojF_BBX6Fy",
        "outputId": "576059cf-57e2-493d-f129-e73232aab0d8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, your name is Laksh.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model in genai.list_models():\n",
        "  print(model.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "V_jHvLuQYCdp",
        "outputId": "cfe0089b-aa92-49ef-fb0e-77cb8acb5b9c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/chat-bison-001\n",
            "models/text-bison-001\n",
            "models/embedding-gecko-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro\n",
            "models/gemini-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-pro-exp-0801\n",
            "models/gemini-1.5-pro-exp-0827\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-exp-0827\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-1.5-flash-8b-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0924\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-exp-1206\n",
            "models/gemini-exp-1121\n",
            "models/gemini-exp-1114\n",
            "models/learnlm-1.5-pro-experimental\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/aqa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model in genai.list_models():\n",
        "  if model.name == 'models/gemini-1.5-flash':\n",
        "    print(model)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "hezReduMYWee",
        "outputId": "c33078a9-7645-4406-cc61-0412a3cbac66"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(name='models/gemini-1.5-flash',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Flash',\n",
            "      description=('Alias that points to the most recent stable version of Gemini 1.5 Flash, our '\n",
            "                   'fast and versatile multimodal model for scaling across diverse tasks.'),\n",
            "      input_token_limit=1000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Explore generation parameters**"
      ],
      "metadata": {
        "id": "jZsGOImbYhjX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font face=\"Georgia\" size=5 color=' #3F33FF'> **Output Length**<font>\n",
        "\n",
        "\n",
        "When generating text with an LLM, the output length affects cost and performance. Generating more tokens increases computation, leading to higher energy consumption, latency, and cost.\n",
        "\n",
        "\n",
        "To stop the model from generating tokens past a limit, you can specify the max_output_tokens parameter when using the Gemini API. Specifying this parameter does not influence the generation of the output tokens, so the output will not become more stylistically or textually succinct, but it will stop generating tokens once the specified length is reached.\n",
        "\n",
        "Prompt engineering may be required to generate a more complete output for your given limit."
      ],
      "metadata": {
        "id": "rRKW0AaSYmdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "short_model = genai.GenerativeModel(\n",
        "    'gemini-1.5-flash',\n",
        "    generation_config=genai.GenerationConfig(max_output_tokens=300))\n",
        "\n",
        "response = short_model.generate_content('Write a 1000 word essay on the VIT University in modern society.')\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "1RlVGlq8Yw4e",
        "outputId": "11720462-41b7-44db-b5e6-3cbb6cb6f124"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## VIT University in Modern Society: A Crucible of Innovation and Global Engagement\n",
            "\n",
            "Vellore Institute of Technology (VIT), a private university situated in Vellore, Tamil Nadu, India, stands as a significant player in modern Indian higher education and, increasingly, on the global stage.  Its impact extends beyond its campus, shaping not only the lives of its students but also contributing to national development and engaging with global challenges. This essay will explore VIT's multifaceted role in contemporary society, examining its contributions to technological advancement, its influence on societal transformation, and its evolving relationship with the broader global community.\n",
            "\n",
            "One of VIT's most prominent contributions is its role in fostering technological innovation. Recognizing the imperative for a technologically advanced workforce, VIT has invested heavily in state-of-the-art infrastructure, research facilities, and industry collaborations.  Its numerous research centers, focusing on areas such as nanotechnology, biotechnology, and artificial intelligence, actively engage in cutting-edge research, producing publications in leading international journals and securing patents. This commitment to research translates into tangible outcomes, nurturing a culture of innovation that extends beyond the university walls.  Graduates equipped with practical skills and a research-oriented mindset are contributing significantly to India's burgeoning technological sector, driving economic growth and enhancing the nation's global competitiveness.  The university's focus on entrepreneurship, through incubation centers and mentorship programs, further accelerates this process, fostering the creation of startups and contributing to a vibrant ecosystem of innovation.\n",
            "\n",
            "Beyond technological\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font face=\"Georgia\" size=6 color=' #800080'> **Another Example**<font>\n"
      ],
      "metadata": {
        "id": "HVakURE_ZEjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = short_model.generate_content('Write a short poem on the importance of Humanity in modern society.')\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "JklJuRpIZGeT",
        "outputId": "faac9872-44fb-4ffa-b7a4-5fae7e9bdd5a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In screens' cold glow, a world unseen,\n",
            "Where clicks and likes obscure the sheen\n",
            "Of human touch, a gentle hand,\n",
            "A helping heart, across the land.\n",
            "\n",
            "Forget the score, the fleeting trend,\n",
            "Let empathy and kindness blend.\n",
            "For in our shared humanity's embrace,\n",
            "We find the strength, the hope, the grace.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font face=\"Georgia\" size=6 color=' #6E2C00'> **Exploring for more**<font>"
      ],
      "metadata": {
        "id": "cnS-U9qXcfqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = short_model.generate_content('Write a short story on the importance of 5G network.')\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "NX0BVyzedJnM",
        "outputId": "c081c72e-3bc9-423e-d7a1-882f648330ca"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The old woman, Elara, hunched over her worn datapad, its screen flickering with the glacial pace of the 3G connection.  She was trying to video call her grandson, Kai, a budding surgeon in the bustling metropolis of Neo-Kyoto, a city humming with the speed of 5G.  The image pixelated, froze, then dissolved into a shower of static.  Another failed attempt.\n",
            "\n",
            "Elara sighed, the weight of distance heavy on her heart. She lived in the remote farming village of Oakhaven, nestled deep in the emerald valleys, untouched – and underserved – by modern technology.  Their lives were dictated by the slow crawl of outdated networks, a stark contrast to Kai’s life, a whirlwind of instantaneous communication and advanced medical procedures.\n",
            "\n",
            "Kai, through the occasional, frustratingly fragmented call, often described his work. He spoke of remote surgeries guided by 5G-enabled robotics, of real-time diagnostic imaging transmitted across continents with the clarity of a crystal, and of the collaborative efforts of surgeons across the globe, all facilitated by the network's lightning-fast speed and unparalleled reliability.  He spoke of saving lives, of a world where distance wasn't a barrier to healing.\n",
            "\n",
            "One day, a government initiative reached Oakhaven.  A team of engineers, spurred by a national drive to bridge the digital divide, arrived with their equipment.  For weeks, they worked tirelessly, stringing fiber optic cables through the valleys\n"
          ]
        }
      ]
    }
  ]
}