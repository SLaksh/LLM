# -*- coding: utf-8 -*-
"""Translator App(chains) - Langchain-AgenticAI-daytwo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Tp_X7iG2mdmppHurW8QwunevwCXMeW6T

# **Building the Translator: Code & Explanation**
"""

!pip install -q langchain langchain-google-genai google-generativeai

from google.colab import userdata
import os
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import ChatPromptTemplate
from langchain.chains import LLMChain # The basic building block chain

# Load API Key and Initialize LLM
try:
    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')
    os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY
    # Initialize with a low temperature for more predictable translations
    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash-lite", temperature=0.3)
    print("API Key loaded and LLM initialized successfully.")
    setup_ok = True
except Exception as e:
    print(f"ERROR: Could not load API key or initialize LLM. {e}")
    print("Please ensure GOOGLE_API_KEY is set in Colab Secrets.")
    setup_ok = False

"""**A chain is an independent block that can call the LLM**

# **Create a structured prompt for a chat-based language model**
"""

prompt_template_text = """
Translate the following text into {target_language}.
Your response should ONLY contain the translated text, nothing else.


Text:
"{text_to_translate}"


Translation:
"""


prompt = ChatPromptTemplate.from_template(prompt_template_text)
print("Prompt Template created.")

"""# **Create a Functional LLM chain that connects the LLM and the prompt**"""

# 2. Create the LLMChain
# This chain links our prompt template with our Gemini LLM.
translation_chain = LLMChain(llm=llm, prompt=prompt)
print("Translation Chain created.")

## LangChain wraps these into a pipeline, so when you give input to the chain, it:
###.  Fill in the prompt template with your variables
###   Sends the full prompt to the LLM
####. Returns the generated response

# 3. Run the Chain with Examples
text_to_translate_1 = "LangChain helps developers build amazing AI applications."
target_language_1 = "Tamil"

# Example 1
print(f"\n--- Translating to {target_language_1} ---")
print(f"Input: {text_to_translate_1}")
response1 = translation_chain.invoke({
    "text_to_translate": text_to_translate_1,
    "target_language": target_language_1
})


print(f"Output: {response1['text']}") # LLMChain puts the result in the 'text' key

# Example 2
print(f"\n--- Translating to {target_language_1} ---")
print(f"Input: {text_to_translate_1}")
response1 = translation_chain.invoke({
    "text_to_translate": "This is Agentic AI Workshop Batch 7",
    "target_language": "tamil"
})


print(f"Output: {response1['text']}") # LLMChain puts the result in the 'text' key

# Example 3
print(f"\n--- Translating to {target_language_1} ---")
print(f"Input: {text_to_translate_1}")
response1 = translation_chain.invoke({
    "text_to_translate": "Have a Great Day",
    "target_language": "French"
})


print(f"Output: {response1['text']}") # LLMChain puts the result in the 'text' key

# Example 4
print(f"\n--- Translating to {target_language_1} ---")
print(f"Input: {text_to_translate_1}")
response1 = translation_chain.invoke({
    "text_to_translate": "Passez une excellente journ√©e",
    "target_language": "english"
})


print(f"Output: {response1['text']}") # LLMChain puts the result in the 'text' key