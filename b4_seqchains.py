# -*- coding: utf-8 -*-
"""B4-SeqChains.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AN-2S_1dIllRg7S78euvR1kqoestAXDI
"""

!pip install -q langchain langchain-google-genai google-generativeai

from google.colab import userdata
import os
import time
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import ChatPromptTemplate
from langchain.chains import LLMChain
from langchain.chains import SimpleSequentialChain # Import SimpleSequentialChain

# Load API Key and Initialize LLM
try:
    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')
    os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash-lite",
        temperature=0.9,
        max_tokens=300
    )
    print("API Key loaded and LLM initialized successfully.")
    setup_ok = True
except Exception as e:
    print(f"ERROR: Could not load API key or initialize LLM. {e}")
    print("Please ensure GOOGLE_API_KEY is set in Colab Secrets.")
    setup_ok = False

from langchain.chains import TransformChain

def delay_function(inputs):
        """This function pauses execution and then passes the input through."""
        print("\n--- Pausing for 1s to avoid rate limiting... ---")
        time.sleep(1)
        return inputs

delay_chain_1 = TransformChain(input_variables=["article_output"], output_variables=["article_output"], transform=delay_function)
delay_chain_2 = TransformChain(input_variables=["summary_output"], output_variables=["summary_output"], transform=delay_function)

print("Delay Chain created.")

# --- Chain 1: Article Generator ---
article_prompt_template_text = """
You are an expert blog generator.
Given the topic: "{topic}", generate a compelling and unique article of about 300 words.


Article:
"""
article_prompt = ChatPromptTemplate.from_template(article_prompt_template_text)
article_chain = LLMChain(llm=llm, prompt=article_prompt)
print("Article Chain created.")

# --- Chain 2: Summary Chain ---
summary_prompt_template_text = """
You are an expert paraphraser and a summary generator.
Based on the following article:
"{article_output}"
Generate a concise summary of the article in 40 to 50 words

Summary:
"""
summary_prompt = ChatPromptTemplate.from_template(summary_prompt_template_text)
summary_chain = LLMChain(llm=llm, prompt=summary_prompt)
print("summary Chain created.")

# --- Chain 3: MCQ Generator Chain ---
mcq_gen_prompt_template_text = """
You are a subject matter expert who specializes in generating multiple choice questions (MCQs).
Based on the following summary:
"{summary_output}"
Generate five MCQs in the following example format:

Example:
Q1. Question Desc
Option 1. Option 1
Option 2. Option 2
Option 3. Option 3
Option 4. Option 4
Key: Index of the correct option (1, 2, 3, or 4)

MCQs:
"""
mcq_gen_prompt = ChatPromptTemplate.from_template(mcq_gen_prompt_template_text)
mcq_gen_chain = LLMChain(llm=llm, prompt=mcq_gen_prompt)
print("mcq_gen Chain created.")

# --- Create the SimpleSequentialChain ---
overall_chain = SimpleSequentialChain(
    chains=[article_chain, delay_chain_1, summary_chain, delay_chain_2, mcq_gen_chain],
    verbose=True
)
print("Overall SimpleSequentialChain created.")

input_topic = "our solar system"

final_response = overall_chain.invoke(input_topic)

print(final_response)